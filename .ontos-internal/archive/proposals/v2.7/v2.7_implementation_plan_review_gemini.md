# Review of v2.7 Implementation Plan v1.0.0

**Author:** Gemini (as a technical co-founder)
**Date:** 2025-12-19
**Status:** Approved with minor recommendations

---

This is an exceptionally thorough and well-crafted implementation plan. The level of detail, inclusion of open questions, and clear alignment with the master plan's strategic goals are commendable. This document provides a solid foundation for development.

Here is my detailed review, including feedback on the plan and answers to the open questions.

---

### **1. Overall Assessment**

`[APPROVE]`

The v2.7 implementation plan is excellent. It is comprehensive, detailed, and demonstrates a deep understanding of the project's architectural invariants. The breakdown of features into schema changes, logic, tooling, and testing is clear and actionable. The proactive identification of open questions and potential risks makes the plan robust. I am confident that a developer can execute this plan with a high degree of success. My feedback below is focused on ratifying the excellent recommendations made and adding minor refinements.

---

### **2. Responses to Open Questions**

I will vote on each open question as requested, providing my rationale.

| ID | Question | My Vote & Rationale |
| :--- | :--- | :--- |
| **2.3.A** | What types can USE `describes`? | **Approve Recommendation (Option 2: Atom only).** This maintains a strict, unambiguous type hierarchy. The feature's purpose is to link documentation to the underlying *code or concrete files* that change, which are represented as Atoms. Allowing other types to use `describes` would blur this clean separation. |
| **2.3.B** | What types can BE described? | **Approve Recommendation (Option 1: Atom only).** The goal is to detect code drift. Staleness checking is most meaningful when applied to mutable, concrete implementations (Atoms). Describing more abstract types like 'strategy' would be less valuable and add complexity. |
| **2.3.C** | Can a doc describe itself? | **Approve Recommendation (Option 2: Disallow).** A self-reference is semantically meaningless for staleness checking and provides no value to the graph. It should be treated as a validation error to prevent user confusion. |
| **2.4.A** | How to determine atom last modified? | **Approve Recommendation (Option A with D's fallback).** This is the only truly robust solution. `os.path.getmtime` is fundamentally broken by Git operations. Using `git log` is the correct, philosophically aligned approach. The fallback to `mtime` with a warning is a good defensive measure for non-git edge cases. |
| **2.4.B** | Date comparison precision? | **Approve Recommendation (Option 1: Day precision).** This avoids a world of pain with timezones and parsing complexity. Comparing at the date level is sufficient and matches the user's mental model of "I verified this today." |
| **2.4.C** | When does staleness check run? | **Approve Recommendation (Option 4: All).** The check is computationally cheap. The value of providing this crucial information at every stage of the developer workflow (map generation, archiving, pre-push) far outweighs the minor performance cost. |
| **2.6.A** | How does user update verified date? | **Approve Recommendation (Option D: Manual + Command).** This strikes the perfect balance. The manual edit is the base case that reinforces the "explicit curation" philosophy. The `ontos_verify.py` command provides a quality-of-life shortcut without compromising intent. |
| **2.8.A** | Staleness audit section format? | **Approve Recommendation (Option 3: Both).** The inline `[STALE]` flag provides immediate, at-a-glance context. The separate summary table provides a single, actionable place to see all stale documentation. This is excellent UX. |
| **2.8.B** | Verify script structure? | **Approve Recommendation (Option 1: New script for now).** This is a pragmatic, incremental approach. It delivers the feature for v2.7 without creating a hard dependency on the v2.8 unified CLI. It can be easily integrated later. |
| **2.9.A** | Migration strategy? | **Approve Recommendation (Option A for v2.7).** The `describes` feature is non-breaking and opt-in. A silent rollout is the best user experience. Adding prompts or helpers in a future version is the right way to handle this. |
| **3.3.A** | When to regenerate history? | **Approve Recommendation (Option A: On context map generation).** This elegantly simplifies the system's mental model. `ontos_generate_context_map.py` becomes the single source of truth for generating *all* computed views of the graph. |
| **3.3.B** | Date source for sorting? | **Approve Recommendation (Option 3: Frontmatter with filename fallback).** This is robust. It prioritizes explicit, authoritative metadata from the frontmatter while gracefully handling legacy logs that may not have it. |
| **3.3.C** | History file location? | **Approve Recommendation (Option 1: Current location).** Correct. Avoid breaking changes and user churn when there is no compelling reason to move the file. |
| **3.3.D** | Git tracking for history? | **Approve Recommendation (Option C: Committed + marked).** This is the best of all worlds. The history is available on clone (vital for a local-first tool), and the "GENERATED FILE" header clearly communicates how to handle merge conflicts (regenerate, don't manually resolve). |
| **3.5.A** | Consolidation vs history gen? | **Approve Recommendation (Independent).** A clean separation of concerns. `consolidate` manages the lifecycle of logs (active -> archive). `generate_context_map` creates a view from the *entire set* of logs. They are related but distinct operations. |
| **3.6.A** | Merge conflict helper? | **Approve Recommendation (Option 1: No helper for v2.7).** The manual workflow is simple and should be documented. A dedicated helper script is likely over-engineering at this stage and should only be built if user feedback proves it's necessary. |

---

### **3. Further Improvements & Considerations**

The plan is very strong, but here are a few points to refine or consider during implementation.

1.  **Specify `ontos_verify.py --all` Behavior:** The plan notes the `--all` flag as "interactive." This carries a risk of a "yes-to-all" footgun where a user verifies documents without reading them. The implementation should be more specific: ideally, it should iterate through each stale file and prompt for verification individually. A less-desirable but acceptable alternative would be to simply list all stale files and exit, forcing the user to verify them one by one.

2.  **Add Caching to `get_git_last_modified`:** The performance risk of git command execution is noted. A simple and effective mitigation is to use an in-memory cache (a `dict`) within the `get_git_last_modified` function. This would ensure that for the duration of a single script run, you only execute `git log` once for any given file path.

3.  **Test for Circular Dependencies:** The "Risks" section lists "Circular describes," but the testing strategy doesn't explicitly mention a test case for it (e.g., Doc A describes Doc B, and Doc B describes Doc A). A unit test should be added to ensure the validation logic catches this semantic error.

4.  **Graceful Git Failure:** The implementation of `get_git_last_modified` must be robust. It should wrap the `subprocess.run` call in a `try...except` block. If the command fails (e.g., `git` not installed, or not a git repo), it should log a clear warning and proceed with the `mtime` fallback as planned.

---

### **4. Conclusion**

This is a model implementation plan. It is detailed, well-reasoned, and demonstrates a clear understanding of the project's strategic goals. With the minor refinements suggested above, it is ready for execution. I give it my full approval.
