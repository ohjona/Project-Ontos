"""
Context map generation command.

Orchestrates the generation of Ontos_Context_Map.md using
extracted core and io modules.

Phase 2 Decomposition - Created from Phase2-Implementation-Spec.md Section 4.10
"""

from __future__ import annotations
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple

from ontos.core.validation import ValidationOrchestrator
from ontos.core.tokens import estimate_tokens, format_token_count
from ontos.core.types import DocumentData, ValidationResult


@dataclass
class GenerateMapOptions:
    """Configuration options for context map generation."""
    output_path: Optional[Path] = None
    strict: bool = False
    include_staleness: bool = True
    include_timeline: bool = True
    include_lint: bool = False
    max_dependency_depth: int = 5
    dry_run: bool = False


def generate_context_map(
    docs: Dict[str, DocumentData],
    config: Dict[str, Any],
    options: GenerateMapOptions = None
) -> Tuple[str, ValidationResult]:
    """Generate the context map markdown content.

    Args:
        docs: Dictionary of parsed documents
        config: Configuration dictionary
        options: Generation options

    Returns:
        Tuple of (content string, validation result)
    """
    options = options or GenerateMapOptions()

    # Run validation
    validator = ValidationOrchestrator(docs, {
        "max_dependency_depth": options.max_dependency_depth,
        "allowed_orphan_types": config.get("allowed_orphan_types", ["atom", "log"]),
    })
    result = validator.validate_all()

    # Generate content sections
    sections = []

    # Header with provenance
    sections.append(_generate_header(config))

    # Document table
    sections.append(_generate_document_table(docs))

    # Validation messages (if any)
    if result.errors or result.warnings:
        sections.append(_generate_validation_section(result))

    # Dependency tree
    sections.append(_generate_dependency_tree(docs))

    # Timeline (if enabled)
    if options.include_timeline:
        sections.append(_generate_timeline(docs))

    # Assemble content
    content = "\n\n".join(filter(None, sections))

    return content, result


def _generate_header(config: Dict[str, Any]) -> str:
    """Generate context map header with provenance."""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    project_name = config.get("project_name", "Project")
    
    return f"""# {project_name} Context Map

> Auto-generated by Ontos v3.0.0
> Last updated: {timestamp}

This document provides a navigable index of all tracked documents in the knowledge graph."""


def _generate_document_table(docs: Dict[str, DocumentData]) -> str:
    """Generate document listing table."""
    if not docs:
        return "## Documents\n\nNo documents found."
    
    lines = [
        "## Documents",
        "",
        "| Path | ID | Type | Status |",
        "|------|-----|------|--------|",
    ]
    
    # Sort docs by path
    sorted_docs = sorted(docs.values(), key=lambda d: str(d.filepath))
    
    for doc in sorted_docs:
        doc_type = doc.type.value if hasattr(doc.type, 'value') else str(doc.type)
        doc_status = doc.status.value if hasattr(doc.status, 'value') else str(doc.status)
        lines.append(f"| {doc.filepath} | {doc.id} | {doc_type} | {doc_status} |")
    
    return "\n".join(lines)


def _generate_validation_section(result: ValidationResult) -> str:
    """Generate validation messages section."""
    lines = ["## Validation"]
    
    if result.errors:
        lines.append("")
        lines.append("### Errors")
        for error in result.errors:
            lines.append(f"- ❌ **{error.doc_id}**: {error.message}")
    
    if result.warnings:
        lines.append("")
        lines.append("### Warnings")
        for warning in result.warnings:
            lines.append(f"- ⚠️ **{warning.doc_id}**: {warning.message}")
    
    return "\n".join(lines)


def _generate_dependency_tree(docs: Dict[str, DocumentData]) -> str:
    """Generate dependency tree visualization."""
    lines = ["## Dependency Tree"]
    
    if not docs:
        lines.append("\nNo dependencies to display.")
        return "\n".join(lines)
    
    # Find root nodes (no dependents)
    all_deps = set()
    for doc in docs.values():
        all_deps.update(doc.depends_on)
    
    roots = [doc_id for doc_id in docs if doc_id not in all_deps]
    
    if not roots:
        lines.append("\nAll documents have dependencies (possible cycle).")
        return "\n".join(lines)
    
    lines.append("")
    for root in sorted(roots)[:10]:  # Limit for readability
        lines.append(f"- **{root}**")
        if root in docs:
            for dep in docs[root].depends_on[:5]:
                lines.append(f"  - {dep}")
    
    return "\n".join(lines)


def _generate_timeline(docs: Dict[str, DocumentData]) -> str:
    """Generate activity timeline."""
    lines = ["## Recent Activity"]
    
    # Filter to logs only
    logs = [doc for doc in docs.values() 
            if (doc.type.value if hasattr(doc.type, 'value') else str(doc.type)) == "log"]
    
    if not logs:
        lines.append("\nNo session logs found.")
        return "\n".join(lines)
    
    # Sort by date (extract from ID if possible)
    sorted_logs = sorted(logs, key=lambda d: d.id, reverse=True)[:10]
    
    lines.append("")
    for log in sorted_logs:
        lines.append(f"- `{log.id}`")
    
    return "\n".join(lines)
